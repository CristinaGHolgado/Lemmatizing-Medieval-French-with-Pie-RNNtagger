{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "old_french_pie.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OQUbqfVPrLdR",
        "DlJYfF8qrYGT",
        "bvcZO6EN_w8s",
        "anxtKYJtOHqx",
        "R_RFIPOzOO6y",
        "-qVNWVRROgtZ"
      ],
      "authorship_tag": "ABX9TyNtnKfCOmTG/RwSum4HkzIf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristinaGHolgado/old-french-with-pie-rnntagger/blob/master/old_french_pie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CytkTAyqrBzD"
      },
      "source": [
        "## **Install the library**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQUbqfVPrLdR"
      },
      "source": [
        "#### **Install Pie (v0.3.6)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7h5rhhxh0NB"
      },
      "source": [
        "pip install nlp-pie==0.3.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlJYfF8qrYGT"
      },
      "source": [
        "####**Set the path to** /pie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31SvH5V5jV5Z"
      },
      "source": [
        "# path should be /usr/local/lib/python3.7/dist-packages/pie' in GColab if using Python 3.7 \n",
        "# if different, find and set the path to /pie \n",
        "import os\n",
        "\n",
        "def set_path_pie(path):\n",
        "  \"\"\" Set path to Pie folder for training or tagging\n",
        "  \"\"\"\n",
        "  if not str(os.getcwd()).endswith('/pie'):\n",
        "    os.chdir(path)\n",
        "    print(f\"Path set to : {os.getcwd()}\")\n",
        "  else:\n",
        "    pass"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XsH3chNlMmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb071597-877d-4194-fcfd-d8d6726a0ae5"
      },
      "source": [
        "pie_path = '/usr/local/lib/python3.7/dist-packages/pie'\n",
        "set_path_pie(pie_path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Path set to : /usr/local/lib/python3.7/dist-packages/pie\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvcZO6EN_w8s"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKm7Mc9eOVB7"
      },
      "source": [
        "#### **Set custom training parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aANZ8dt1kZEf"
      },
      "source": [
        "## Modify parameters & options if necessary (*)\n",
        "\n",
        "defaultSettingsFile = \"default_settings.json\" # // name or path to the .json file training parameters *\n",
        "\n",
        "out_json = defaultSettingsFile.split(\".\")[0] + \"_\" + data_to_train + \".json\"\n",
        "\n",
        "data_to_train = 'pos' # // train pos (traning data column name) *\n",
        "modelname = \"oldfrench_model\" # // output model name *\n",
        "inputpath = \"token_tags_corpus.csv\" # // input trainig data path or filename *\n",
        "colnames = f'[\"token\", \"{data_to_train}\"]' # // column names in trainig data\n",
        "\n",
        "customized_train_params = True # // If True the folowing parameters will be used * :\n",
        "nb_epoch = 50 # *\n",
        "checks_per_epoch = 0  # *\n",
        "batch_size = 2  # *\n",
        "lower_opt = 'false' # lowercase target tokens *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv2pOL80HP0S"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def setParams():\n",
        "  \"\"\" Set training parameters for 'default_settings.json'\n",
        "  \"\"\"\n",
        "  with open(defaultSettingsFile, \"r\") as source_params, open(out_json, \"w\") as out: # open default training settings json file\n",
        "      for line in source_params:\n",
        "        if '\"modelname\"' in line:\n",
        "          line = line.replace('\"model\"', f'\"{modelname}\"')\n",
        "          print(line)\n",
        "        if '\"input_path\"' in line:\n",
        "          line = line.replace('\"\"', f'\"{inputpath}\"') # path (unix-like expression) to files with training data [default_settings.json]\n",
        "          print(line)\n",
        "        if '\"tasks_order\":' in line:\n",
        "          line = line.replace('[\"lemma\", \"pos\"]',f'{colnames}') # Expected order of tasks for tabreader if no header [default_settings.json]\n",
        "          print(line)\n",
        "        if '\"name\": \"lemma\"' in line:\n",
        "          line = line.replace('\"lemma\"',f'\"{data_to_train}\"')\n",
        "          print(line)\n",
        "        \n",
        "        if customized_train_params == True:\n",
        "          if '\"epochs\"' in line:\n",
        "            line = re.sub('[0-9]*\\,', str(nb_epoch) + \",\" , line)\n",
        "            print(line)\n",
        "          if '\"batch_size\"' in line:\n",
        "            line = re.sub('[0-9]*\\,', str(batch_size) + \",\" , line)\n",
        "            print(line)\n",
        "          if '\"checks_per_epoch\"' in line:\n",
        "            line = re.sub('[0-9]*\\,', str(checks_per_epoch) + \",\" , line)\n",
        "            print(line)\n",
        "          if '\"lower\"' in line:\n",
        "            line = line.replace('true', lower_opt)\n",
        "            print(line)\n",
        "\n",
        "        out.write(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ8FNTqhNkcV"
      },
      "source": [
        "print(f\"Parameters : \\n{out_json}\") # Display parameters\n",
        "print()\n",
        "setParams()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahe4pH-Bkppb"
      },
      "source": [
        "####  **Run training & download model after training**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzHXlW2mZBBv"
      },
      "source": [
        "# Run after setting trainig parameters in the default settings json file & upload training data\n",
        "!pie train default_settings_pos.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0WT2mTUsvTC"
      },
      "source": [
        "from google.colab import files\n",
        "import glob\n",
        "lastmodel = modelname + \"*.tar\"\n",
        "get_model = \"\".join(glob.glob(lastmodel)) # 1 model\n",
        "files.download(get_model) # automatically download model after training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZQ5jxfe_3m4"
      },
      "source": [
        "### **Tagging**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anxtKYJtOHqx"
      },
      "source": [
        "#### **Log into your Drive to choose the files to be tagged**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRNDnXICT4bS",
        "outputId": "553119b3-7466-4c87-922b-d75e6d607a96"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_RFIPOzOO6y"
      },
      "source": [
        "####**Modify *models/tag_pipe.py* to skip tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX-uWxPDb15g"
      },
      "source": [
        "def noTokenizing():\n",
        "  with open(\"scripts//tag_pipe.py\",\"r\") as py, open(\"scripts//tag_pipe2.py\",\"w\") as out_py:\n",
        "    f = py.readlines()\n",
        "    for l in f:\n",
        "      if \"line = line.split()\" in l:\n",
        "        l = l.replace(\"line = line.split()\", \"line = line.split()\\n            line = [' '.join(item for item in line)]\")\n",
        "      out_py.write(l)\n",
        "def checkPy():\n",
        "  with open(\"scripts//tag_pipe.py\",\"r\") as py:\n",
        "    f = py.readlines()\n",
        "    for l in f:\n",
        "      if \"line = [' '.join(item for item in line)])\" in l:\n",
        "        pass\n",
        "      else:\n",
        "        noTokenizing()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93bmEAbEMBxv"
      },
      "source": [
        "*   **Run the cell below to modify the code in `tag_pie.py` automatically**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBVMC7Kb2-iB"
      },
      "source": [
        "!mv \"scripts//tag_pipe.py\" \"scripts//tag_pipe_src.py\"\n",
        "!mv \"scripts//tag_pipe2.py\" \"scripts//tag_pipe.py\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2qDoTdKIU7z"
      },
      "source": [
        "noTokenizing()\n",
        "checkPy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucT3h7k8KSFr"
      },
      "source": [
        "* **Or replace line 24**\n",
        "```\n",
        "23        else:\n",
        "24            line = line.split()\n",
        "```\n",
        "to\n",
        "```\n",
        "23        else:\n",
        "24            line = [' '.join(item for item in line)]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qVNWVRROgtZ"
      },
      "source": [
        "####**Tagging corpus files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX_OQePZO59W"
      },
      "source": [
        "# path to unnanotated corpus\n",
        "tokens_path = '/content/gdrive/My Drive/RNNTagger(tagger)/tsv_files/tokens/*tokens.csv' \n",
        "# model to be used for tagging\n",
        "model = '10ep2bat.tar'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_VfBymmPzRz"
      },
      "source": [
        "* **Tag multiple files**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyMuC0JMU2Hz"
      },
      "source": [
        "import subprocess\n",
        "import glob\n",
        "import os, sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MnFTxw-P0Sw"
      },
      "source": [
        "def run_tagging(path):\n",
        "  \"\"\" Load model and tag corpus\n",
        "  path : str\n",
        "    absolute path to folder containing unnanotated corpus\n",
        "  \"\"\"\n",
        "  all_files = glob.glob(path)\n",
        "  print(f\"{len(all_files)} files found\")\n",
        "  nbFile = 0\n",
        "\n",
        "  for file in all_files:\n",
        "    print(file)\n",
        "    outputname = \"/content/gdrive/My Drive/tagged_corpus_nlppie/\" + file.split(\"/\")[-1].replace('tokens.csv','_tagged_pie.csv')\n",
        "    command = \"cat '\" + file + \"' | \" + \"pie tag-pipe \" + f\"{model} > '\" + outputname + \"'\"\n",
        "    nbFile += 1\n",
        "    print(f\"Fichier no. : {nbFile}\")\n",
        "    !{command}\n",
        "\n",
        "run_tagging(tokens_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3sJexyuSDIv"
      },
      "source": [
        "* **Tag a single file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o26e-TLsSIlm"
      },
      "source": [
        "inputFile = 'inputfile.csv' # // input file to tag\n",
        "output_tagged = 'tagged_tokens.txt' # // output tagged file name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h95C4z1EC3R9"
      },
      "source": [
        "%%shell\n",
        "cat {inputFile} | pie tag-pipe {model} > {output_tagged}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}